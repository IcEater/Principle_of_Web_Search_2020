{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  \n",
    "from lxml import etree \n",
    "import pickle\n",
    "import os\n",
    "from IPython.core.display import display, HTML\n",
    "import timeit\n",
    "import jieba\n",
    "\n",
    "class MySearcherC7V0:\n",
    "    \"\"\"\n",
    "    第六次课升级的搜索类版本：\n",
    "    1、避免重复查询相同词\n",
    "    2、尽量减少lower()的运行次数\n",
    "    3、用文档刷词构建缓存\n",
    "    4、去掉search里的文档扫描过程\n",
    "    \"\"\"\n",
    "    def __init__(self, scale=1):\n",
    "        self.docs = []\n",
    "        self.load_data()\n",
    "        self.docs *= scale\n",
    "        self.cache = {}\n",
    "        self.vocab = set()\n",
    "        self.lower_preprocess()\n",
    "        self.build_cache()\n",
    "    \n",
    "    def build_cache(self):\n",
    "        doc_id = 0\n",
    "        for doc in self.docs:\n",
    "            doc_word_set = set()\n",
    "            for word in jieba.cut(\n",
    "                doc[3]\n",
    "            ):\n",
    "                if word not in doc_word_set:\n",
    "                    result_item = [doc_id, self.score(doc, word)]\n",
    "                    if word not in self.cache:\n",
    "                        self.cache[word] = [result_item]\n",
    "                    else:\n",
    "                        self.cache[word].append(result_item)\n",
    "                    self.vocab.add(word)\n",
    "                    doc_word_set.add(word)\n",
    "            doc_id += 1\n",
    "        \n",
    "        for word in self.cache:\n",
    "            self.cache[word].sort(key=lambda x: x[1], reverse=True)\n",
    "                    \n",
    "    def lower_preprocess(self):\n",
    "        for doc_id in range(len(self.docs)):\n",
    "            self.docs[doc_id].append(\n",
    "                (self.docs[doc_id][1] \n",
    "                 + ' ' \n",
    "                 + self.docs[doc_id][2]).lower()\n",
    "            )\n",
    "        \n",
    "    def search(self, keyword):\n",
    "        keyword_l = keyword.lower()\n",
    "        if keyword_l in self.cache:\n",
    "            sorted_result = self.cache[keyword_l] \n",
    "        else:\n",
    "            sorted_result = []\n",
    "        return sorted_result\n",
    "    \n",
    "    def simple_test(self):\n",
    "        assert(len(self.search('tiktok')) > 1)\n",
    "    \n",
    "    def load_data(self):\n",
    "        data_filename = 'news_list.dat'\n",
    "        if os.path.exists(data_filename):\n",
    "            with open(data_filename,'rb') as f:\n",
    "                self.docs += pickle.load(f)\n",
    "#                 self.docs = self.docs + pickle.load(f)\n",
    "        else:\n",
    "            url = 'http://news.163.com/special/0001386F/rank_tech.html'  \n",
    "            headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36 Edg/85.0.564.63'}\n",
    "            r = requests.get(url, headers=headers)  \n",
    "            sel = etree.HTML(r.text) \n",
    "            link_set = set()\n",
    "            news_list = []\n",
    "            count = 0\n",
    "            for item in sel.xpath('//td/a'):  \n",
    "                title = item.text\n",
    "                link = item.attrib['href']\n",
    "            #     print(link, title)\n",
    "                if link not in link_set:\n",
    "                    r = requests.get(link, headers=headers)  \n",
    "                    sel = etree.HTML(r.text)  \n",
    "                    text_block = sel.xpath('//div[@id=\"endText\"]') \n",
    "                #     print(''.join(text_block[0].itertext()))\n",
    "                    if text_block:\n",
    "                        content = ''.join(text_block[0].xpath('./p/text()'))\n",
    "                        title = sel.xpath('//h1/text()')[0]\n",
    "                        self.docs.append([link, title, content])\n",
    "                    link_set.add(link)\n",
    "                count += 1\n",
    "                if count % 15 == 0:\n",
    "                    print(count, 'processed.')\n",
    "            with open(data_filename,'wb') as f:\n",
    "                pickle.dump(self.docs, f)\n",
    "    \n",
    "    def highlight(self, text, keyword):\n",
    "        idx = text.lower().find(keyword.lower())\n",
    "        result = text\n",
    "        if idx >= 0:\n",
    "            ori_word = text[idx:idx+(len(keyword))]\n",
    "            result = text.replace(ori_word, '<span style=\"color:red\";>{}</span>'.format(ori_word))\n",
    "        return result\n",
    "    \n",
    "    def score(self, item, keyword):\n",
    "        return (item[1].lower().count(keyword.lower()) * 5 \n",
    "          + item[2].lower().count(keyword.lower()) * 3)\n",
    "    \n",
    "    def render_search_result(self, keyword):\n",
    "        count = 0\n",
    "        for item in self.search(keyword):\n",
    "            count += 1\n",
    "        #     print(count, '[{}] {}'.format(item[1], \n",
    "        #         highlight(news_list[item[0]][1], keyword)))\n",
    "            display(HTML('{} [{}] {}'.format(count, item[1], \n",
    "                self.highlight(self.docs[item[0]][1], keyword))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "searcherv0_1x = MySearcherC7V0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1 [113] 腾讯系虎牙<span style=\"color:red\";>斗鱼</span>终于合并，但快手抖音B站已杀来"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "2 [74] <span style=\"color:red\";>斗鱼</span>虎牙宣布合并：双方市值各占新公司50%，腾讯控股"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "searcherv0_1x.render_search_result('斗鱼')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'日媒 拆解 华为 5G 基站 ： 中企 零部件 约 占 一半   美 零部件 占 3 成'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(jieba.cut('日媒拆解华为5G基站：中企零部件约占一半 美零部件占3成'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'腾讯 系 虎牙 斗鱼 终于 合并 ， 但 快手 抖音 B站 已 杀 来'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(jieba.cut_for_search('腾讯系虎牙斗鱼终于合并，但快手抖音B站已杀来'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.load_userdict('dict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dict.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile dict.txt\n",
    "B站\n",
    "抖音\n",
    "快手"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B绔�\n",
      "鎶栭煶\n",
      "蹇�鎵�\n"
     ]
    }
   ],
   "source": [
    "!cat dict.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySearcherC7V1(MySearcherC7V0):\n",
    "    \"\"\"\n",
    "    1、初始化过程加载自定义分词词典\n",
    "    2、改为使用cut_for_search进行分词\n",
    "    \n",
    "    3、对查询分词\n",
    "    4、对分词结果取posting\n",
    "    5、对posting lists取交集\n",
    "    6、将posting保存格式改成只用doc_id\n",
    "    \"\"\"\n",
    "    def __init__(self, scale=1):\n",
    "        self.docs = []\n",
    "        self.load_data()\n",
    "        self.docs *= scale\n",
    "        self.cache = {}\n",
    "        self.vocab = set()\n",
    "        self.lower_preprocess()\n",
    "        self.build_cache()\n",
    "        jieba.load_userdict('dict.txt')\n",
    "    \n",
    "    def build_cache(self):\n",
    "        doc_id = 0\n",
    "        for doc in self.docs:\n",
    "            doc_word_set = set()\n",
    "            for word in jieba.cut_for_search(\n",
    "                doc[3]\n",
    "            ):\n",
    "                if word not in doc_word_set:\n",
    "                    result_item = doc_id\n",
    "                    if word not in self.cache:\n",
    "                        self.cache[word] = set([result_item])\n",
    "                    else:\n",
    "                        self.cache[word].add(result_item)\n",
    "                    self.vocab.add(word)\n",
    "                    doc_word_set.add(word)\n",
    "            doc_id += 1\n",
    "    \n",
    "    def search(self, query):\n",
    "        result = None\n",
    "        for keyword in jieba.cut(query.lower()):\n",
    "            if keyword in self.cache:\n",
    "                if result is None:\n",
    "                    result = self.cache[keyword]\n",
    "                else:\n",
    "                    result = result & self.cache[keyword]\n",
    "            else:\n",
    "                result = set([])\n",
    "                break\n",
    "                \n",
    "        if result is None:\n",
    "            result = set([])\n",
    "        \n",
    "        sorted_result = self.rank(query, result)\n",
    "        \n",
    "#         keyword_l = keyword.lower()\n",
    "#         if keyword_l in self.cache:\n",
    "#             sorted_result = self.cache[keyword_l] \n",
    "#         else:\n",
    "#             sorted_result = []\n",
    "        \n",
    "        return sorted_result\n",
    "    \n",
    "    def rank(self, query, result_set):\n",
    "        result = []\n",
    "        for doc_id in result_set:\n",
    "            result.append([doc_id, \n",
    "                self.score(self.docs[doc_id],\n",
    "                          query)])\n",
    "        result.sort(key=lambda x: x[1], reverse=True)\n",
    "        return result       \n",
    "    \n",
    "    def score(self, item, query):\n",
    "        score = 0\n",
    "        #todo cut\n",
    "        for keyword in jieba.cut(query):\n",
    "            score += item[1].lower().count(keyword.lower()) * 5 \\\n",
    "                      + item[2].lower().count(keyword.lower()) * 3\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set([1,2,3])\n",
    "b = set([2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2, 3}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a & b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a | b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "searcherv1_1x = MySearcherC7V1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[63, 260],\n",
       " [134, 134],\n",
       " [53, 77],\n",
       " [3, 69],\n",
       " [23, 69],\n",
       " [83, 57],\n",
       " [146, 46],\n",
       " [123, 46],\n",
       " [80, 41],\n",
       " [133, 40],\n",
       " [231, 39],\n",
       " [50, 26],\n",
       " [77, 21],\n",
       " [114, 21],\n",
       " [57, 17],\n",
       " [104, 12],\n",
       " [108, 12],\n",
       " [58, 9]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcherv1_1x.search('华为手机')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1 [260] 手机失窃致资金被盗！当事人：损失都追回"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "2 [134] 华为Mate40来了 硬刚iPhone12！买哪个？网友吵起来了"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "3 [77] 富士康万元招人，新iPhone要和华为\"绝版\"正面对决"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "4 [69] 没大惊喜，但iPhone12这次诚意满满，我心动了"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "5 [69] 没大惊喜，但iPhone12这次诚意满满，我心动了"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "6 [57] iPhone 12今天没来，苹果早就告诉你要迟到，不过A14芯片提前来了"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "7 [46] 传台积电获批，可以继续向华为供货，但不含手机SoC"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "8 [46] 1.7万元！腾讯奖励万名员工每人一台华为折叠屏手机"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "9 [41] 华为欧洲高管：虽受美国制裁 有信心继续为欧洲5G客户服务"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "10 [40] 华为抢购芯片+手机热卖，三星Q3营收或达570亿美元"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "11 [39] 拼多多插入京东、苏宁腹地"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "12 [26] 日本电子元件企业TDK向美国申请对华为供货"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "13 [21] 北邮乔秀全：5G的消费级杀手应用可能诞生于XR设备"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "14 [21] 鸿蒙OS升级机型曝光:麒麟9000设备将率先更新升级"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "15 [17] 2020胡润中国10强消费电子企业：华为第一 小米第二"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "16 [12] 国内第四大运营商中国广电在京成立 将发行5G192号段"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "17 [12] 国内第四大运营商中国广电在京成立 将发行5G192号段"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "18 [9] 中兴称5G基站芯片实现商用，禁运时自给率几乎为零"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "searcherv1_1x.render_search_result('华为手机')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
